{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIDS based on Network Flow Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is network flow and flow measurement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A network flow consists of all network packets that have the same flow identifier (ID). The flow ID can be extracted from the packet header and is usually defined by the 5-tuple: source and destination IP addresses, source and destination ports, and the protocol that is used at the transport layer.\n",
    "\n",
    "<center>\n",
    "<img src=\"images/counting/5tuple.png\"/>\n",
    "</center>\n",
    "\n",
    "Flow measurement tries to gather metadata on existing flows like the presence of certain features, the average volume, or peak volumes. Measuring the flow data is indispensable in a number of applications such as traffic analysis, network visibility, congestion control, heavy-hitter detection, anomaly detection, and intrusion detection.\n",
    "\n",
    "Flow-measurement based NIDS use the network flow data (flow size, flow volume, flow features, etc.) for intrusion detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For network flow measurement on high-speed networks, especially when the focus is on hardware, we need to prioritize two things to enable processing at line speed: high-speed lookup and high-speed counting. Keeping the memory and storage requirement within the on-chip memory is the best way to reduce the latency in lookup and counting, and this can be done by using efficient probabilistic lookup data structures and approximate counting techniques. In this tutorial, we focus only on high-speed lookup. However, a useful introduction to approximate counting is given in the closing notebook.\n",
    "\n",
    "In this exercise we take flow size/flow volume as our parameter and we consider measuring/counting the flow size/flow volume of flow IDs to detect an anomaly and intrusion. We define **flow size** as the number of packets and **flow volume** as the byte volume of packets. We start with flow size first and later with flow volume.\n",
    "\n",
    "This exercise will walk you through the simplest of data structures and will illustrate how malicious flows can be detected through flow measurements.\n",
    "\n",
    "Similar to the earlier notebooks, don't forget to preload the dataset first !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is loaded\n"
     ]
    }
   ],
   "source": [
    "from lib.dataset import NIDSDataset\n",
    "\n",
    "data_file = 'data/dataset_packets_v2.npy'\n",
    "labels_file = 'data/dataset_labels_v1.npy'\n",
    "\n",
    "dataset = NIDSDataset(data_file, labels_file)\n",
    "\n",
    "print(\"Dataset is loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to keep count for every flow ID that is passing. Therefore an array will be used that stores all the count values. In Python, we can make use of a dictionary (a key-value pair data structure) to store the flow IDs and their corresponding flow sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# INITIALISE THE COUNTERS TO ZERO\n",
    "\n",
    "wordcounter=0\n",
    "flowid = \"\"\n",
    "\n",
    "# Python dictionary to store the flowid and its sizes. \n",
    "# Here we are taking only flow sizes \n",
    "# (i.e; the size of  each packet is taken as 1)\n",
    "library = {} \n",
    "\n",
    "# loop over all datasets\n",
    "for d in dataset:\n",
    "    \n",
    "    wordcounter = 0\n",
    "    flowid = \"\"\n",
    "    flowvolume = \"\"\n",
    "    flowid_complete = 0\n",
    "    # loop over all words\n",
    "    for word in d:\n",
    "\n",
    "        # examine if Ethertype is 0x0800 - in link layer header\n",
    "        # if Ethertype is not equal to 0x0800, break\n",
    "        \"\"\"WRITE code here\"\"\"\n",
    "        \n",
    "        # examine if proto is tcp or udp 6/17 - in network layer header\n",
    "        # if proto is not tcp or udp, break\n",
    "        \"\"\"WRITE code here\"\"\"\n",
    "        \n",
    "        # extract Total length (flow volume) - in network layer header\n",
    "        # hint: convert to hex and concatanate the bytes\n",
    "        # (we will not be using flow colume in this exercise, but needed in the next.)\n",
    "        \"\"\"WRITE code here\"\"\"\n",
    "                \n",
    "        # Extract flowid. Flowid is source IPv4 address, dest IPv4 address, \n",
    "        # source port, dest port\n",
    "        # hint: convert numbers to hex and remove the leading 0x. \n",
    "        #       then concatenate together\n",
    "        \n",
    "        # extract Source Address - in network layer header\n",
    "        \"\"\"WRITE code here\"\"\"\n",
    "        \n",
    "        # extract Destination Address - in network layer header\n",
    "        \"\"\"WRITE code here\"\"\"\n",
    "        \n",
    "        # extract source port estination port - in network layer header\n",
    "        \"\"\"WRITE code here\"\"\"\n",
    "\n",
    "        # examine Destination port - in transport layer header\n",
    "        # set the flag flowid_complete to 1 when the flowid is complete, and break the loop\n",
    "        # If the flowid is complete, update the dictionary\n",
    "        \"\"\"WRITE code here\"\"\"\n",
    "        \n",
    "        wordcounter += 1\n",
    "    \n",
    "    # Check if the extracted flowid is present in library. if not\n",
    "    # add the flowid with a size 1. If present, increment the size by 1.\n",
    "    if(flowid_complete==1):\n",
    "        \"\"\"WRITE code here\"\"\"\n",
    "        \n",
    "    # end of iteration over words\n",
    "\n",
    "# PRINTS all the flowids along with the sizes\n",
    "for flowid in library:  \n",
    "    print(flowid, '->', library[flowid])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine a possible malicious flow, a maximum can be put on the flow size. Setting the exact number of the threshold is a delicate task and requires experience.\n",
    "\n",
    "In the next exercise, we set a threshold of **20** to determine which of the flowids exhibit anomalous behaviour by exceeding the allocated bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Print the flow IDs that exceed a threshold\"\"\"\n",
    "\n",
    "threshold = 20\n",
    "\n",
    "# PRINTS all the flowids along with the sizes\n",
    "for flowid in library:\n",
    "    if(library[flowid]>threshold):\n",
    "        print(flowid, '->', library[flowid])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><div style=\"background-color: #b9ffb9; padding: 10px,20px;  width: 80%;\">The code above should report that there are 195 FlowIDs in the dataset, of which 10 exceed the allowed bandwidth.</div></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<center>\n",
    "Continue with the <a href=\"21_counting.ipynb\">next notebook</a> in a new browser tab.<br/><br/>\n",
    "<img src=\"images/footer.png\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
