{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIDS based on Network Flow Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is network flow and flow measurement?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A network flow consists of all network packets that have the same flow identifier (ID). The flow ID can be extracted from the packet header and consists, and is usually defined by the 5-tuple. \n",
    "\n",
    "<hr/>\n",
    "<center>\n",
    "<img src=\"images/counting/5tuple.png\"/>\n",
    "</center>\n",
    "\n",
    "Flow measurement is a collection of flow data. Measuring the flow data is useful in a number of applications such as traffic analysis, network visibility, congestion control, heavy-hitter detection, anomaly detection, and intrusion detection.\n",
    "\n",
    "Flow-measurement based NIDS use the network flow data (flow size, flow volume, flow features, etc.) for intrusion detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we take flow size/flow volume as our parameter and we consider measuring/counting the flow size/flow volume of flow IDs to detect an anomaly and intrusion. We define flow size as the number of packets and flow bytes as the byte volume of packets. We start with flow size first and later with flow volume.\n",
    "\n",
    "This exercise will walk you through the simplest of data structures to show how malicious can be detected through flow measurements."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do we measure the flow size/volume?\n",
    "We require a counter array to count the flow size. In software, we can make use of a dictionary to store the flow IDs and corresponding flow sizes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "import import_ipynb\n",
    "from lib.dataset import NIDSDataset\n",
    "\n",
    "data_file = 'data/packets.npy'\n",
    "labels_file = 'data/labels.npy'\n",
    "\n",
    "dataset = NIDSDataset(data_file, labels_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# INITIALISE THE COUNTERS TO ZERO\n",
    "\n",
    "wordcounter=0\n",
    "flowid = \"\"\n",
    "library = {} # Library to store the flowid and sizes. Here we are taking only flow sizes (i.e; the size of\n",
    "             # each packet is taken as 1)\n",
    "\n",
    "# loop over all datasets\n",
    "for d in dataset:\n",
    "\n",
    "    decision_is_made = 0 # decision_is_made = 1 when ethertype is not 0x0800 or packet is neither TCP nor UDP\n",
    "                         # decision_is_made = 2 when the flow ID is extracted\n",
    "    wordcounter = 0\n",
    "    flowid = \"\"\n",
    "\n",
    "    # loop over all words\n",
    "    for word in d:\n",
    "        # stop parsing if a decission is made\n",
    "        if decision_is_made == 0:\n",
    "\n",
    "            # examine if Ethertype is 0x0800 - in link layer header\n",
    "            # if Ethertype is not equal to 0x0800, break\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "            # examine if proto is tcp or udp 6/17 - in network layer header\n",
    "            # if proto is not tcp or udp, break\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "                    \n",
    "            # Extract flowid. flowid is (sorce address, dest address, source port, dest port)\n",
    "            # hint: convert to hex and remove 0x. concatanate the addresses and ports\n",
    "            \n",
    "            # extract Source Address - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "\n",
    "            # extract Destination Address - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "            \n",
    "            # extract source port estination port - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "\n",
    "            # examine Destination port - in transport layer header\n",
    "            # If the flowid is complete, break out of the loop\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "        wordcounter += 1\n",
    "    \n",
    "    if(decision_is_made==2):\n",
    "        #check if the flowid is in the library and\n",
    "        # if it is present increment flow size by 1, and if not present add the new \n",
    "        # flowid with a size 1. \n",
    "        \"\"\" WRITE CODE here\"\"\"\n",
    "        \n",
    "    # end of iteration over words\n",
    "\n",
    "# PRINTS all the flowids along with the sizes\n",
    "for flowid in library:  \n",
    "    print(flowid, '->', library[flowid])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do any of the flows exhibits anomalous behaviour?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 20.2\n",
    "\n",
    "we set a threshold to determine which of the flowids exhibits anomalous behaviour by exceeding the allocated bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' WRITE code here '"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Print the flow IDs that exceeds a threshold\"\"\"\n",
    "\n",
    "threshold = 10\n",
    "\n",
    "# iterate through the library and print all the flowids from the librabry that exceeds the threshold\n",
    "\"\"\" WRITE code here \"\"\"\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making use of a hashtable\n",
    "If we want to reduce the memory footprint, we can hash the flowids to locate an index to store the flowids and flowsize. Python actually can make a hashtable of it, where the flow IDs and associated flow size are stored as key-value pairs. In HDL, there are no such concept as hashtables, so we have to implement the hash tables manually.\n",
    "\n",
    "<hr/>\n",
    "<center>\n",
    "<img src=\"images/counting/hashmap.png\"/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to address hash collisions?\n",
    "Since we are trimming down the hashed value according to the length of the hash table, there will be collisions. We need to take measures such as chaining to avoid hash collisions in hashtables. C\n",
    "\n",
    "Chaining is simple and is like a linked list, where each index can include a separate list with many elements. And the advantage is that hash table never fills up, we can always add more elements to the chain.\n",
    "\n",
    "<hr/>\n",
    "<center>\n",
    "<img src=\"images/counting/chaining.png\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 20.3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" HASHTABLE \"\"\"\n",
    "\n",
    "import array\n",
    "import hashlib\n",
    "\n",
    "n = 256 # length of the hashtable\n",
    "array = [None] * n\n",
    "\n",
    "\"\"\" Define functions here for the hashtable \"\"\"\n",
    "\n",
    "def _hash(key):\n",
    "    \"\"\" Md5 hash function to calculate the index\"\"\"\n",
    "    n=256\n",
    "    md5 = hashlib.md5(str(hash(key)).encode('utf-8'))\n",
    "    return int(md5.hexdigest(), 16) % n\n",
    "    \n",
    "def add_ht(key, value):\n",
    "    \"\"\"Add a value to hashtable by its key and update the contents if the cell is not empty\"\"\"\n",
    "    index = _hash(key)\n",
    "    if array[index] is not None:\n",
    "        # WRITE the code to Check if the flowid present in the [key,value] pair in the array[index] is equal to \n",
    "        # the incoming flowid. if equal, then add the value to the existing value.\n",
    "        # If the flowids are not equal, then we have to do the chaining and append the new\n",
    "        # element to the list in the array[index].\n",
    "        \"\"\" WRITE code here \"\"\"\n",
    "        \n",
    "        \n",
    "    else: \n",
    "        # If the index is empty, creare an empty list in array[index] and \n",
    "        # append the key-value pair to the list.\n",
    "        \"\"\" WRITE code here \"\"\"\n",
    "        \n",
    "        \n",
    "def query_ht(key):\n",
    "    \"\"\"Get a value by key\"\"\"\n",
    "    index = _hash(key)\n",
    "    if array[index] is None:\n",
    "        return 0\n",
    "    else:\n",
    "        # iterate through all key-value-pairs and find if the flowid exist. \n",
    "        # If exists then return its value. # If no return was done during iteration, \n",
    "        # that means flowid does not exist. Then return 0\n",
    "        \"\"\" WRITE code here \"\"\"\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 20.3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Now, reading the dataset again to update the hashtable. you can Copy and \"\"\"\n",
    "\"\"\" paste the code from the previous Exercise. \"\"\"\n",
    "\"\"\" In this exercise we will be taking the actual flow volume instead of flow size = 1 \"\"\"\n",
    "wordcounter=0\n",
    "flowid = \"\"     # flow id\n",
    "flowvolume = \"\" # flow volume (Total length from the ip header)\n",
    "flowlist = []  # keeps a list to store flows\n",
    "\n",
    "# loop over all datasets\n",
    "for d in dataset:\n",
    "\n",
    "    decision_is_made = 0 # decision_is_made = 1 when ethertype is not 0x0800 or packet is neither TCP nor UDP\n",
    "                         # decision_is_made = 2 when the flow ID is extracted\n",
    "    wordcounter = 0\n",
    "    flowid = \"\"\n",
    "    flowvolume = \"\" \n",
    "\n",
    "    # loop over all words\n",
    "    for word in d:\n",
    "        # stop parsing if a decission is made\n",
    "        if decision_is_made == 0:\n",
    "\n",
    "            # examine if Ethertype is 0x0800 - in link layer header\n",
    "            # if Ethertype is not equal to 0x0800, break loop\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "            # examine if proto is tcp or udp 6/17 - in network layer header\n",
    "            # if proto is not tcp or udp, break loop\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "                    \n",
    "            # extract Total length (flow volume) - in network layer header\n",
    "            # hint: convert to hex and concatanate the bytes\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "                \n",
    "            # Extract flowid. flowid is (sorce address, dest address, source port, dest port)\n",
    "            # hint: convert to hex and remove 0x. concatanate the addresses and ports\n",
    "            \n",
    "            # extract Source Address - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "\n",
    "            # extract Destination Address - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "            \n",
    "            # extract source port estination port - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "\n",
    "            # examine Destination port - in transport layer header\n",
    "            # If the flowid is complete, break out of the loop\n",
    "            \"\"\" WRITE code here \"\"\"\n",
    "            \n",
    "            \n",
    "        wordcounter += 1\n",
    "        \n",
    "        \n",
    "    # Convert the flow volume to integer\n",
    "    \"\"\" WRITE code here \"\"\"\n",
    "    \n",
    "        \n",
    "    if flowid not in flowlist:\n",
    "        flowlist.append(flowid)\n",
    "\n",
    "\n",
    "    \"\"\" Updating the table \"\"\"\n",
    "    # add flowid and flowvolume to the hashtable using the function\n",
    "    \"\"\" WRITE code here (1 line of code)\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for anomalies\n",
    "#### Exercise 20.3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WRITE code here '"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Print the flow IDs that exceeds a threshold\"\"\"\n",
    "threshold = 600\n",
    "# iterate through the flowlist and print those flowids having total volume greater than the threshold\n",
    "\"\"\"WRITE code here \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<center>\n",
    "Continue with the <a href=\"01_readingframes.ipynb\">next notebook</a> in a new browser tab.<br/><br/>\n",
    "<img src=\"images/footer.png\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
