{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtable\n",
    "\n",
    "The 'Dictionary-approach' that was used in the previous exercise works very nicely. Python actually makes a hashtable (or hash map) of it, where the flow IDs and associated flow size are stored as key-value pairs. In HDL, there are no such concepts like hashtables, so the hash table has to be implemented manually.\n",
    "\n",
    "When a FlowID comes in, it is first hashed. For the sake of completeness it is mentioned that **a hash function** is a function that transforms an input of an arbitrary length to an output of a fixed length, called the **digest** (or hash).\n",
    "\n",
    "The digest is subsequently used as an address to a memory. The value that resides on that memory address is the **value**, where the FlowID is the **key**. \n",
    "\n",
    "<center>\n",
    "<img src=\"images/21_hashtable.png\"/>\n",
    "</center>\n",
    "\n",
    "If we want to reduce the memory footprint, we can hash the flowids to locate an index to store the flowids and flowsize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to address hash collisions?\n",
    "\n",
    "When a hash function provides a 256 bits hash, this would imply that the memory is 2<sup>256</sup> deep. As this is barely feasible, only of subset of a hash function (or even a tiny hash function) is used.\n",
    "\n",
    "Since we are trimming down the hash according to the length of the hash table, there will be **collisions**.\n",
    "\n",
    "> A **collision** occurs when two different FlowIDs point to the same value as the (part of the) hash digest is identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to mimic the hardware behaviour an try to (re-)build a hashtable. For hash algorithm the MD5 algorithms is chosen. This function generates a 128-bit digest. \n",
    "\n",
    "To keep the resources usage under control, only the 8 least significant bits of the hash digest are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the quick brown fox jumps over the lazy dog => 0\n",
      "the quick brown fox jumps over the lazy dog => 0\n",
      "the quick brown fox jumps over the lazy dog => 0\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "HASHTABLE_DEPTH = 4096 # depth of the hashtable\n",
    "memory = [None] * HASHTABLE_DEPTH\n",
    "\n",
    "def _hash(key):\n",
    "    \"\"\" Md5 hash function to calculate the index\"\"\"\n",
    "    md5 = hashlib.md5(str(hash(key)).encode('utf-8'))\n",
    "    return int(md5.hexdigest(), 16) % HASHTABLE_DEPTH\n",
    "    \n",
    "def add_ht(key, value):\n",
    "    \"\"\" Function to add elements to the hash table \"\"\"\n",
    "    # write to code to obtain a numeric hash value for the 'key'\n",
    "    placeholder = 0\n",
    "\n",
    "    # write the code to check if a value already exists on the obtained address\n",
    "    # if the address is not set yet, set it to the value\n",
    "    # if the address is already set, overwrite it with the sum of both values\n",
    "        \n",
    "def query_ht(key):\n",
    "    \"\"\" Function to query elements from the hash table \"\"\"\n",
    "    # write to code to obtain a numeric hash value for the 'key'\n",
    "    placeholder = 0\n",
    "\n",
    "    # return zero (0x0) if no entry exists\n",
    "    # if an entry exists, return the corresponding value\n",
    "\n",
    "    return 0\n",
    "        \n",
    "\n",
    "# Set a 'key'\n",
    "key = \"the quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "# Query the 'key'\n",
    "queried_value = query_ht(key)\n",
    "print(\"%s => %d\" % (key, queried_value))\n",
    "        \n",
    "# Add the 'key'\n",
    "add_ht(key, 123)\n",
    "queried_value = query_ht(key)\n",
    "print(\"%s => %d\" % (key, queried_value))\n",
    "\n",
    "# Add the 'key'\n",
    "add_ht(key, 321)\n",
    "queried_value = query_ht(key)\n",
    "print(\"%s => %d\" % (key, queried_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><div style=\"background-color: #b9ffb9; padding: 10px,20px;  width: 80%;\">The code above should report 0, 123, and 444.</div></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets run the exercise using the **dataset**. Loop through the dataset again and determine which of the flowids exhibits anomalous behaviour by exceeding the allocated bandwidth. However, this time use the self-fabricated hashtable.\n",
    "\n",
    "**Note**: This time we are going to extract the actual flow volumes from the dataset\n",
    "\n",
    "(**HINT**: you can recover most of the work from your previous exercises.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.dataset import NIDSDataset\n",
    "\n",
    "data_file = 'data/dataset_packets_v2.npy'\n",
    "labels_file = 'data/dataset_labels_v1.npy'\n",
    "\n",
    "dataset = NIDSDataset(data_file, labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total flows =  0\n",
      "Number of malicious flows =  0\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Now, reading the dataset again to update the hashtable. you can Copy and \"\"\"\n",
    "\"\"\" paste the code from the previous Exercise. \"\"\"\n",
    "\"\"\" In this exercise we will be taking the actual flow volume instead of flow size = 1 \"\"\"\n",
    "memory = [None] * HASHTABLE_DEPTH\n",
    "wordcounter=0\n",
    "flowid = \"\"     # flow id\n",
    "flowvolume = \"\" # flow volume (Total length from the ip header)\n",
    "flowlist = []  # keeps a list to store flows\n",
    "\n",
    "# loop over all datasets\n",
    "for d in dataset:\n",
    "\n",
    "    decision_is_made = 0 # decision_is_made = 1 when ethertype is not 0x0800 or packet is neither TCP nor UDP\n",
    "    wordcounter = 0\n",
    "    flowid = \"\"\n",
    "    flowvolume = \"\" \n",
    "    flowid_complete = 0\n",
    "\n",
    "    # loop over all words\n",
    "    for word in d:\n",
    "        # stop parsing if a decission is made\n",
    "        if decision_is_made == 0:\n",
    "\n",
    "            # examine if Ethertype is 0x0800 - in link layer header\n",
    "            # if Ethertype is not equal to 0x0800, break loop\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "            # examine if proto is tcp or udp 6/17 - in network layer header\n",
    "            # if proto is not tcp or udp, break loop\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "                    \n",
    "            # extract Total length (flow volume) - in network layer header\n",
    "            # hint: convert to hex and concatanate the bytes\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "                \n",
    "            # Extract flowid. flowid is (sorce address, dest address, source port, dest port)\n",
    "            # hint: convert to hex and remove 0x. concatanate the addresses and ports\n",
    "            \n",
    "            # extract Source Address - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "\n",
    "            # extract Destination Address - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "            \n",
    "            # extract source port estination port - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "\n",
    "            # examine Destination port - in transport layer header\n",
    "            # If the flowid is complete, set the flag flowid_complete to 1 and break out of the loop\n",
    "            \"\"\" WRITE code here \"\"\"\n",
    "            \n",
    "            \n",
    "        wordcounter += 1\n",
    "        \n",
    "    if(flowid_complete == 1): \n",
    "        if flowid not in flowlist:\n",
    "            flowlist.append(flowid)\n",
    "            \n",
    "        # Convert the flow volume to integer\n",
    "        \"\"\" WRITE code here \"\"\"\n",
    "\n",
    "\n",
    "        \"\"\" Updating the table \"\"\"\n",
    "        # add flowid and flowvolume to the hashtable using the function\n",
    "        \"\"\" WRITE code here \"\"\"\n",
    "        \n",
    "\n",
    "\"\"\"Print the flow IDs that exceeds a threshold\"\"\"\n",
    "threshold = 1000\n",
    "\n",
    "# iterate through the flowlist and print those flowids having total volume greater than the threshold\n",
    "count_flows = 0\n",
    "count_malicious = 0\n",
    "\"\"\"WRITE code here \"\"\"\n",
    "\n",
    "\n",
    "print(\"Total flows = \",count_flows)\n",
    "print(\"Number of malicious flows = \", count_malicious)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><div style=\"background-color: #b9ffb9; padding: 10px,20px;  width: 80%;\">The code above should report that there are 195 FlowIDs in the dataset, of which 15 exceed the allowed bandwidth.</div></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Chaining\n",
    "\n",
    "In order to handle possible collisions when hashing, measures have to be taken. **Chaining** is a simple solution and is like a linked list. Each each index can include a separate list with many elements. The advantage is that hash table never fills up and we can always add more elements to the chain.\n",
    "\n",
    "<center>\n",
    "<img src=\"images/counting/chaining.png\"/>\n",
    "</center>\n",
    "\n",
    "However, linked lists are not tailored for hardware. Also, is required to store the flowids which drastically increases the memory footprint. Hence collision resistant data structures such as sketches and counting bloom filters are usually employed in hardware implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Optional exercise on chaining\n",
    "\n",
    "The below given exercise is optional. If time permits, you can try out the same exercise given in the previous exercise using chaining in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "HASHTABLE_DEPTH = 4096 # depth of the hashtable\n",
    "memory = [None] * HASHTABLE_DEPTH\n",
    "\n",
    "def _hash(key):\n",
    "    \"\"\" Md5 hash function to calculate the index\"\"\"\n",
    "    md5 = hashlib.md5(str(hash(key)).encode('utf-8'))\n",
    "    return int(md5.hexdigest(), 16) % HASHTABLE_DEPTH\n",
    "    \n",
    "def add_ht(key, value):\n",
    "    \"\"\" Function to add elements to the hash table \"\"\"\n",
    "    # write to code to obtain a numeric hash value for the 'key'\n",
    "    \"\"\" WRITE code here \"\"\"\n",
    "    \n",
    "    # WRITE the code to Check if the flowid present in the [key,value] pair in the array[index] is equal to \n",
    "    # the incoming flowid. if equal, then add the flow size to the value.\n",
    "    # If the flowids are not equal, then we have to think of the chaining and append the new\n",
    "    # element to the list in the array[index].\n",
    "    if memory[index] is not None:  # This index already contain some values.\n",
    "        \"\"\" WRITE code here \"\"\"\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        # If the index is empty, creare an empty list in the array[index] and \n",
    "        # append the key-value pair to the list.\n",
    "        \"\"\" WRITE code here \"\"\"\n",
    "    \n",
    "        \n",
    "def query_ht(key):\n",
    "    \"\"\" Function to query elements from the hash table \"\"\"\n",
    "    # write to code to obtain a numeric hash value for the 'key'\n",
    "    \n",
    "\n",
    "    # return zero (0x0) if no entry exists\n",
    "    # if an entry exists, return the corresponding value\n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading the data set and updating the hashtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" You can Copy and paste the code from the previous Exercise. \"\"\"\n",
    "\n",
    "memory = [None] * HASHTABLE_DEPTH\n",
    "wordcounter=0\n",
    "flowid = \"\"     # flow id\n",
    "flowvolume = \"\" # flow volume (Total length from the ip header)\n",
    "flowlist = []  # keeps a list to store flows\n",
    "\n",
    "# loop over all datasets\n",
    "for d in dataset:\n",
    "\n",
    "    decision_is_made = 0 # decision_is_made = 1 when ethertype is not 0x0800 or packet is neither TCP nor UDP\n",
    "    wordcounter = 0\n",
    "    flowid = \"\"\n",
    "    flowvolume = \"\" \n",
    "    flowid_complete = 0\n",
    "\n",
    "    # loop over all words\n",
    "    for word in d:\n",
    "        # stop parsing if a decission is made\n",
    "        if decision_is_made == 0:\n",
    "\n",
    "            # examine if Ethertype is 0x0800 - in link layer header\n",
    "            # if Ethertype is not equal to 0x0800, break loop\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "            # examine if proto is tcp or udp 6/17 - in network layer header\n",
    "            # if proto is not tcp or udp, break loop\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "                    \n",
    "            # extract Total length (flow volume) - in network layer header\n",
    "            # hint: convert to hex and concatanate the bytes\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "                \n",
    "            # Extract flowid. flowid is (sorce address, dest address, source port, dest port)\n",
    "            # hint: convert to hex and remove 0x. concatanate the addresses and ports\n",
    "            \n",
    "            # extract Source Address - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "\n",
    "            # extract Destination Address - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "            \n",
    "            # extract source port estination port - in network layer header\n",
    "            \"\"\"WRITE code here\"\"\"\n",
    "            \n",
    "\n",
    "            # examine Destination port - in transport layer header\n",
    "            # If the flowid is complete, set the flag flowid_complete to 1 and break out of the loop\n",
    "            \"\"\" WRITE code here \"\"\"\n",
    "            \n",
    "            \n",
    "        wordcounter += 1\n",
    "        \n",
    "    if(flowid_complete == 1): \n",
    "        if flowid not in flowlist:\n",
    "            flowlist.append(flowid)\n",
    "            \n",
    "        # Convert the flow volume to integer\n",
    "        \"\"\" WRITE code here \"\"\"\n",
    "\n",
    "\n",
    "        \"\"\" Updating the table \"\"\"\n",
    "        # add flowid and flowvolume to the hashtable using the function\n",
    "        \"\"\" WRITE code here \"\"\"\n",
    "        \n",
    "\n",
    "\"\"\"Print the flow IDs that exceeds a threshold\"\"\"\n",
    "threshold = 1000\n",
    "\n",
    "# iterate through the flowlist and print those flowids having total volume greater than the threshold\n",
    "count_flows = 0\n",
    "count_malicious = 0\n",
    "\"\"\"WRITE code here \"\"\"\n",
    "\n",
    "\n",
    "print(\"Total flows = \",count_flows)\n",
    "print(\"Number of malicious flows = \", count_malicious)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><div style=\"background-color: #b9ffb9; padding: 10px,20px;  width: 80%;\">The code above should report that there are 195 FlowIDs in the dataset, of which 15 exceed the allowed bandwidth.</div></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<center>\n",
    "Continue with the <a href=\"22_counting.ipynb\">next notebook</a> in a new browser tab.<br/><br/>\n",
    "<img src=\"images/footer.png\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
