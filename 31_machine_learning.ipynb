{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79db9ebd",
   "metadata": {},
   "source": [
    "## ML for simple input features\n",
    "\n",
    "### Problem\n",
    "One of the typical challenges in ML is feature selection: Which features will be used characterize the input samples and train the models? The features should be representative, contain sufficient information for the model to be able to make an informed decision, but should also avoid redundancy or useless information. Therefore, traditional features for NIDS include:\n",
    "\n",
    "- The IPv4 source and destination addresses;\n",
    "- The TCP source and destination ports;\n",
    "- Statistics on the number of packets/bytes in a network flow (count, average, STD, duration, ...);\n",
    "- Network flags (e.g. TCP flags);\n",
    "- ...\n",
    "\n",
    "Typically, these features are provided alongside the raw network traffic data in a dataset. Most ML and DL models therefor use those features for training models, obtaining excellent results. This approach however has some considerable drawbacks:\n",
    "\n",
    "- Different datasets provide different features, complicating inter-dataset comparison;\n",
    "- Extracting these features requires significant preprocessing of raw traffic data.\n",
    "\n",
    "While the first point is more of a general concern, the second is especially relevant when dealing with hardware: When dealing with high-speed real-time network traffic, there are only limited resources available for dealing with feature extraction. This calls for either optimized routines to extract a limited number of specific features, or for an alternative.\n",
    "\n",
    "\n",
    "### Alternative: Raw traffic-based features\n",
    "One alternative is to use the raw input traffic itself as features, instead of deriving the features from the traffic: We call such features *raw traffic-based features* (RTF). This is what we will do in this notebook.\n",
    "\n",
    "While using RTF in some sense limits the amount of possible features, there are still three choices to be made:\n",
    "- What packet bytes to use;\n",
    "- How many packet bytes to use;\n",
    "- How many packets to use.\n",
    "\n",
    "In this exercise, we will use the first 64 bytes of each individual packet as input features. That includes the header, as well as potentially a small part of the payload. Using 64B input features therefore should provide all header information about the network flow: Source and destination information, protocol information (including flags), packet size, ... We leave the DL model to parse and use this information to its own liking. Moreover, choosing specifically 64B for input features provides several other advantages:\n",
    "\n",
    "- 64 bytes is relatively small, limiting the required hardware resources;\n",
    "- 64 bytes is a very convenient number of bytes to work with on a hardware level.\n",
    "\n",
    "#### Raw traffic-based features on hardware\n",
    "One major advantage of RTF over traditional NIDS features is that they are very easy to extract in real-time on hardware. Instead of having to design intricate counting and parsing architectures, all you need to start collecting RTF is a buffer. Simply storing the required amount of packet bytes in the buffer effectively provides the features.\n",
    "\n",
    "#### Raw traffic-based features in software\n",
    "Simulating this behaviour in software requires a chronological iteration over the dataset, while extracting the first 64 bytes from each packet, and storing them in a buffer.\n",
    "\n",
    "For this exercise, we will extract input samples from the CICIDS2017 dataset: While the dataset contains several protocols, such as ARP and ICMP, we are only interested in **TCP and UDP** packets. The trained model we will be using later on is only trained for those transport layer protocols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from lib.dataset import NIDSDataset\n",
    "\n",
    "\n",
    "# Initialize the dataset\n",
    "dset = NIDSDataset(\n",
    "    packets_file=\"./data/dataset_packets_v2.npy\", \n",
    "    labels_file=\"./data/dataset_labels_v1.npy\")\n",
    "\n",
    "# The input_buffer contains all input features\n",
    "input_buffer = []\n",
    "label_buffer = []\n",
    "\n",
    "# Iterate over the dataset, and add all valid input features to the buffer\n",
    "# Accordingly, also extract the label for each of those packets and save it as well\n",
    "\n",
    "for packet in dset:\n",
    "    label = packet.get_label()\n",
    "    input_sample = np.zeros(64)\n",
    "    \n",
    "    # For each valid packet, extract the features to the input_sample and append the input_sample to the \n",
    "    # input_buffer. Do not forget the labels!\n",
    "    # Your code starts here\n",
    "    for word in packet:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"We extracted {} input samples.\".format(len(input_buffer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c015fc49",
   "metadata": {},
   "source": [
    "For use in PyTorch, we need to present the input samples as *tensors*. Additionally, the input dimensionality needs to be slightly changed to be suitable for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensors = []\n",
    "\n",
    "for input_sample in input_buffer:\n",
    "    # Turn the Numpy array into a PyTorch tensor\n",
    "    input_tensor = torch.from_numpy(input_sample)\n",
    "    # Change input dimensionality\n",
    "    input_tensor = input_tensor.view(1, 1, 64)\n",
    "    \n",
    "    input_tensors.append(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ab637",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Once we have extracted a set of input samples from the dataset, we can do inference on the neural network. For this excercise, we use a Convolutional Neural Network (CNN) with 1D convolutions that takes an input of size 64.\n",
    "\n",
    "As the network has already been trained, we only need to load it from the storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lib.nn_model import ExampleCNN1D1x64\n",
    "\n",
    "model = ExampleCNN1D1x64(13)\n",
    "\n",
    "# Load the trained parameters\n",
    "model.load_state_dict(torch.load(\"./data/cnn1d1x64.model\"))\n",
    "\n",
    "# Set the Batch Normalization layers for inference\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c155a757",
   "metadata": {},
   "source": [
    "The output of the above cell gives an overview of the used neural network. Finally, we can run the prepared input tensors through the CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.nn_model import label_mapping\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for input_tensor in input_tensors:\n",
    "    output_tensor = model(input_tensor.float())\n",
    "    \n",
    "    _, predicted = torch.max(output_tensor, 1)\n",
    "    predictions.append(predicted)\n",
    "\n",
    "predictions = torch.stack(predictions, 0).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de9c29f",
   "metadata": {},
   "source": [
    "The *predictions* list contains the class indices corresponding with the predictions. We can visualize the performance of these predictions using a *confusion matrix* (CM). The confusion matrix is a big matrix where each row represents the expected class, while the columns represent the predicted class. It gives a detailed overview of the detection performance for each class. For the visualization of the CM we use the *sklearn* and *matplotlib* packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e8ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Transform the indices to their corresponding class label:\n",
    "labelled_predictions = []\n",
    "for prediction in predictions:\n",
    "    labelled_predictions.append(label_mapping[prediction[0]])\n",
    "\n",
    "# Choose output figure size\n",
    "_, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(label_buffer, labelled_predictions, labels=label_mapping)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=label_mapping)\n",
    "disp.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f81e18",
   "metadata": {},
   "source": [
    "Take a moment to consider your results, as well as their implications. Does the algorithm detect all attacks? Where does it go wrong? Why could that be the case? Would you entrust the security of your network to such an algorithm?\n",
    "\n",
    "As a final step, calculate the classification report from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(label_buffer, labelled_predictions, \n",
    "                            labels=label_mapping, \n",
    "                            target_names=label_mapping,\n",
    "                            digits=4,\n",
    "                            zero_division=0\n",
    "                           ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b3cb35",
   "metadata": {},
   "source": [
    "We expect the following results:\n",
    "\n",
    "- BENIGN F1 = 0.9852\n",
    "- Bot F1 = 0.9011\n",
    "- PortScan = 0.6301\n",
    "- DDoS = 0.9456\n",
    "- F1_weighted_avg = 0.9354\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bfe473",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<center>\n",
    "Continue with the <a href=\"32_machine_learning.ipynb\">next notebook</a> in a new browser tab.<br/><br/>\n",
    "<img src=\"images/footer.png\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1ad03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
