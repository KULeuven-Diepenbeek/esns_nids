{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading network frames as if you were a hardware component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulation of different networking protocols\n",
    "\n",
    "On any network messages are sent as frames. These frames travel over a physical medium (e.g. copper wire, EM radiation (WiFi), ...). When they arrive at a network host, they have to be interpreted and passed on the next component in the chain.\n",
    "\n",
    "<center>\n",
    "<img src=\"images/01_network.png\"/>\n",
    "</center>\n",
    "\n",
    "\n",
    "From a **Networking 101** course (or by common sense ) you should know that files or other datasets are fragmented in a set of frames that are sent one-by-one over the chosen medium. In order to manage this massive amount data that is being sent, different networking protocols are used.\n",
    "\n",
    "These different network protocols typically encapsulate each other. All of these *layers* work in a similar fashion: first they provide meta-data in a **header**; next follows the **payload**. The payload of one layer contains the entire part of the next layer, which again consists of a header and a payload. This concept continues similar to [Rusian Matryoshka dolls](https://en.wikipedia.org/wiki/Matryoshka_doll).\n",
    "\n",
    "<center>\n",
    "<img src=\"images/01_encaps.png\"/>\n",
    "</center>\n",
    "\n",
    "The image above shows a simplified version of the **encapsulation** of the different layers. One important remark to make is that one of the fields in a header sections defines which protocol is used in its payload. This we will use heavily :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "\n",
    "As we are not the first people on the globe that are making hardware for sending and receiving network frames, a lot of components already exists to *translate* the symbols on the physical layer to digital signals. The incoming data is often presented through some bus, which can typically be 8, 32 or even 64 bits. This can be even higher when you're looking at networking hardware in server rooms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "For the purposes of this workshop, we will work with a custom subset of the [CIC-IDS2017](https://www.unb.ca/cic/datasets/ids-2017.html). This is is a dataset that is commonly used in the network intrusion detection community, especially in the literature that performs intrusion detection using machine learning.\n",
    "\n",
    "This dataset roughly contains three kinds of traffic: Unlabelled traffic, labelled benign traffic and labelled attack traffic. Its authors created it by combining benign agents that generated regular, benign traffic with specific attacks. Spreading it over 5 weekdays, from Monday to Friday, each day contains a number of attacks.\n",
    "\n",
    "There are two types of data to encompass all this: Packet CAPture (.pcap) files that contain the binary packet traces as transmitted on the network, as well as Comma Seperated Value (.csv) files that list specific traffic flows alongside their specific features as well as their individual label.\n",
    "For this workshop, we used a subset of the data from Friday. Throughout the exercises you will discover what kinds of traffic are present is our selection.\n",
    "\n",
    "## Interface with the dataset\n",
    "\n",
    "The data we will use for this workshop is stored inside Numpy files (with extension .npy). To allow for easy use, we prepared an interface that provides access to packets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.dataset import NIDSDataset\n",
    "\n",
    "data_file = 'data/dataset_packets_v2.npy'\n",
    "labels_file = 'data/dataset_labels_v1.npy'\n",
    "\n",
    "dataset = NIDSDataset(data_file, labels_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading packets from the dataset simply requires iterating over the dataset in a for-loop, as is shown below.\n",
    "\n",
    "Please note that the previous **code-block** should have been executed prior to the for-loop example. The variable *dataset* is undefined if otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packet_counter = 0\n",
    "\n",
    "for packet in dataset:\n",
    "    packet_counter += 1\n",
    "\n",
    "print(\"Dataset contains {} packets: {}\".format(packet_counter, packet_counter == len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this workshop, we will use data as sequentially presented in words of 32-bits, organised as an array of 4 bytes. This is achieved by iterating over a packet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_packet in dataset:\n",
    "    for word in example_packet:\n",
    "        print(word)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the packets are stored inside a Numpy file, each word is a Numpy-array, which should be considered when manipulating the data. For the sake of manageability, the packets are truncated a 100 bytes: Only the first 100 bytes of packets are stored inside the dataset. Shorter packets of course will contain fewer than 100 bytes, with the missing trailing bytes zero-padded in the Numpy-file. The zero-padding will not show up when iterating over a packet, as this will only provide actual packet bytes. Example: A packet containing 62 bytes will return a Numpy-array with 2 elements as its final word.\n",
    "\n",
    "Each packet has a label: Use the *get_label()* method to get a string that provides the label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_labels = []\n",
    "\n",
    "for packet in dataset:\n",
    "    label = packet.get_label()\n",
    "    \n",
    "    if not (label in traffic_labels):\n",
    "        traffic_labels.append(label) \n",
    "\n",
    "print(\"These are the traffic classes present in the dataset: {}.\".format(\", \".join(traffic_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "<center>\n",
    "Continue with the <a href=\"10_regexes.ipynb\">next notebook</a> in a new browser tab.<br/><br/>\n",
    "<img src=\"images/footer.png\"/>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
